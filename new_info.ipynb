{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76d71fc-26b8-44a5-b9a8-c8766e847207",
   "metadata": {},
   "source": [
    "## class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84b43f2-5b6b-4ff9-af33-a559a6151b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    className = '三年二班'\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def BaseInfo(self):\n",
    "        baseInfo = 'My name is %s, I am a student in %s' % (self.name, MyClass.className)\n",
    "        return baseInfo\n",
    "    \n",
    "    def ComeFrom(self, country, *args):\n",
    "        baseInfo = self.BaseInfo()\n",
    "        comeFrom = baseInfo + '. I come from ' + country + ',' + ','.join(args)\n",
    "        return comeFrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3906d68-eab6-4e5c-893d-865360b3395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is 张三, I am a student in 三年二班. I come from china,chengdu,gaoxinqu,maoyezhongxin\n"
     ]
    }
   ],
   "source": [
    "x = MyClass('张三')\n",
    "print(x.ComeFrom('china', 'chengdu', 'gaoxinqu', 'maoyezhongxin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d517b-0c3a-4574-a4e4-3b4134452a7f",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f032cba-6d40-4a54-aa5e-b64e97c52fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.921\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from collections import Counter  # 为了做投票\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 导入iris数据\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2003)\n",
    "\n",
    "def euc_dis(instance1, instance2):\n",
    "    \"\"\"\n",
    "    计算两个样本instance1和instance2之间的欧式距离\n",
    "    instance1: 第一个样本， array型\n",
    "    instance2: 第二个样本， array型\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    dist = np.sqrt(sum((instance1 - instance2)**2))\n",
    "    return dist\n",
    "    \n",
    " \n",
    "def knn_classify(X, y, testInstance, k):\n",
    "    \"\"\"\n",
    "    给定一个测试数据testInstance, 通过KNN算法来预测它的标签。 \n",
    "    X: 训练数据的特征\n",
    "    y: 训练数据的标签\n",
    "    testInstance: 测试数据，这里假定一个测试数据 array型\n",
    "    k: 选择多少个neighbors? \n",
    "    \"\"\"\n",
    "    # TODO  返回testInstance的预测标签 = {0,1,2}\n",
    "    distances = [euc_dis(x, testInstance) for x in X]\n",
    "    kneighbors = np.argsort(distances)[:k]\n",
    "    count = Counter(y[kneighbors])\n",
    "    return count.most_common()[0][0]\n",
    "\n",
    "# 预测结果。    \n",
    "predictions = [knn_classify(X_train, y_train, data, 3) for data in X_test]\n",
    "correct = np.count_nonzero((predictions==y_test)==True)\n",
    "#accuracy_score(y_test, clf.predict(X_test))\n",
    "print (\"Accuracy is: %.3f\" %(correct/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "548cf5d3-b630-4b68-8f96-f36e568889c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 0, 0, 2, 2, 1, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 1,\n",
       "       1, 2, 1, 1, 2, 2, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 2, 1, 2, 2, 0, 0,\n",
       "       0, 2, 1, 1, 0, 1, 2, 0, 0, 0, 2, 2, 0, 1, 0, 1, 0, 2, 2, 1, 0, 0,\n",
       "       1, 0, 0, 2, 0, 0, 2, 1, 2, 0, 2, 1, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2,\n",
       "       1, 0, 1, 2, 0, 2, 1, 0, 1, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 1,\n",
       "       0, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed725b6-7f15-41da-8ece-c182b5d3e387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 2, 0, 2, 2, 1, 0, 1, 2,\n",
       "       1, 1, 0, 1, 1, 2, 1, 2, 0, 0, 1, 1, 0, 1, 2, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28707808",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba4c7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999 -0.9499999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_57601/1915131316.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  m, c = np.linalg.lstsq(A, y)[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([0, 1, 2, 3])\n",
    "y = np.array([-1, 0.2, 0.9, 2.1])\n",
    "\n",
    "A = np.vstack([x, np.ones(len(x))]).T\n",
    "m, c = np.linalg.lstsq(A, y)[0]\n",
    "print(m, c)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y, 'o', label='Original data', markersize=10)\n",
    "plt.plot(x, m*x + c, 'r', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18d5ffc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression() # linear_model.LinearRegression(fit_intercept=False)\n",
    "clf.fit ([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea59c7f",
   "metadata": {},
   "source": [
    "## Pyspark Transformation算子编程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "157c911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/bin/spark-class: line 71: /Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/bin/java: No such file or directory\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/bin/spark-class: line 96: CMD: bad array subscript\n",
      "head: illegal line count -- -1\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_98507/2948870720.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetMaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local[2]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark0401\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     '''\n\u001b[1;32m      6\u001b[0m     \u001b[0mmap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "if __name__ == '__main__':\n",
    "    conf = SparkConf().setMaster(\"local[2]\").setAppName(\"spark0401\")\n",
    "    sc = SparkContext(conf=conf)\n",
    "    '''\n",
    "    map:\n",
    "        map(func)\n",
    "        将func函数作用到数据集的每个元素上，生成一个新的分布式数据集返回\n",
    "    '''\n",
    "    print(\"***************************map***************************\")\n",
    "    def my_map():\n",
    "        # 创建一个序列\n",
    "        data = [1,2,3,4,5]\n",
    "        # 将序列转换为RDD\n",
    "        rdd1 = sc.parallelize(data)\n",
    "        # 使用函数对RDD进行作用，生成RDD2\n",
    "        rdd2 = rdd1.map(lambda x:x*2)\n",
    "        # 使用collect()讲结果输出\n",
    "        print(rdd2.collect())\n",
    "\n",
    "    my_map()\n",
    "\n",
    "    def my_map2():\n",
    "        a = sc.parallelize([\"dog\",\"tiger\",\"lion\",\"cat\",\"panter\",\"eagle\"])\n",
    "        b = a.map(lambda x:(x,1)) #进来一个x，返回一个(x,1)的形式\n",
    "        print(b.collect())\n",
    "    my_map2()\n",
    "    print(\"***************************filter***************************\")\n",
    "    def my_filter():\n",
    "        #给一个数据\n",
    "        data = [1,2,3,4,5]\n",
    "        rdd1 = sc.parallelize(data)\n",
    "        mapRdd = rdd1.map(lambda x:x**2)\n",
    "        filterRdd = mapRdd.filter(lambda x:x>5)\n",
    "        print(filterRdd.collect())\n",
    "    '''\n",
    "    filter:\n",
    "        filter(func)\n",
    "        返回所有func返回值为true的元素，生成一个新的分布式数据集返回\n",
    "    '''\n",
    "    def my_filter():\n",
    "        data = [1,2,3,4,5]\n",
    "        rdd1 = sc.parallelize(data)\n",
    "        mapRdd = rdd1.map(lambda x:x*2)\n",
    "        filterRdd = mapRdd.filter(lambda x:x > 5)\n",
    "        print(filterRdd.collect())\n",
    "        print(sc.parallelize(data).map(lambda x:x*2).filter(lambda x:x>5).collect())\n",
    "    my_filter()\n",
    "    print(\"***************************flatMap()***************************\")\n",
    "    #Wordcount第一步：\n",
    "    def my_flatMap():\n",
    "        #flatMap,将东西压扁/拆开 后做map\n",
    "        data = [\"hello spark\",\"hello world\",\"hello world\"]\n",
    "        rdd = sc.parallelize(data)\n",
    "        print(rdd.flatMap(lambda line:line.split(\" \")).collect())\n",
    "    my_flatMap()\n",
    "    print(\"***************************groupBy()***************************\")\n",
    "    def my_groupBy():\n",
    "        data = [\"hello spark\",\"hello world\",\"hello world\"]\n",
    "        rdd = sc.parallelize(data)\n",
    "        mapRdd = rdd.flatMap(lambda line:line.split(\" \")).map(lambda x:(x,1))\n",
    "        groupByRdd = mapRdd.groupByKey()\n",
    "        print(groupByRdd.collect())\n",
    "        print(groupByRdd.map(lambda x:{x[0]:list(x[1])}).collect())\n",
    "\n",
    "    my_groupBy()\n",
    "\n",
    "    print(\"***************************reduceByKey()***************************\")\n",
    "    #出现Wordcount结果\n",
    "    def my_reduceByKey():\n",
    "        data = [\"hello spark\", \"hello world\", \"hello world\"]\n",
    "        rdd = sc.parallelize(data)\n",
    "        mapRdd = rdd.flatMap(lambda line: line.split(\" \")).map(lambda x: (x, 1))\n",
    "        reduceByKeyRdd = mapRdd.reduceByKey(lambda a,b:a+b)\n",
    "        print(reduceByKeyRdd.collect())\n",
    "    my_reduceByKey()\n",
    "\n",
    "    print(\"***************************sortByKey()***************************\")\n",
    "    #将Wordcount结果中数字出现的次数进行降序排列\n",
    "    def my_sort():\n",
    "        data = [\"hello spark\", \"hello world\", \"hello world\"]\n",
    "        rdd = sc.parallelize(data)\n",
    "        mapRdd = rdd.flatMap(lambda line: line.split(\" \")).map(lambda x: (x, 1))\n",
    "        reduceByKeyRdd = mapRdd.reduceByKey(lambda a, b: a + b)\n",
    "        #reduceByKeyRdd.sortByKey().collect() 此时是按照字典在排序\n",
    "        #reduceByKeyRdd.sortByKey(False).collect()\n",
    "        #先对对键与值互换位置，再排序，再换位置回来\n",
    "        reduceByKey=reduceByKeyRdd.map(lambda x:(x[1],x[0])).sortByKey(False).map(lambda x:(x[1],x[0])).collect()\n",
    "        print(reduceByKey)\n",
    "    my_sort()\n",
    "\n",
    "    print(\"***************************union()***************************\")\n",
    "    def my_union():\n",
    "        a = sc.parallelize([1,2,3])\n",
    "        b = sc.parallelize([3,4,5])\n",
    "        U = a.union(b).collect()\n",
    "        print(U)\n",
    "    my_union()\n",
    "\n",
    "    print(\"***************************union_distinct()***************************\")\n",
    "    def my_distinct():\n",
    "        #这个和数学并集一样了\n",
    "        a = sc.parallelize([1, 2, 3])\n",
    "        b = sc.parallelize([3, 4, 2])\n",
    "        D = a.union(b).distinct().collect()\n",
    "        print(D)\n",
    "    my_distinct()\n",
    "\n",
    "    print(\"***************************join()***************************\")\n",
    "    def my_join():\n",
    "        a = sc.parallelize([(\"A\", \"a1\"), (\"C\", \"c1\"), (\"D\", \"d1\"), (\"F\", \"f1\"), (\"F\", \"f2\")])\n",
    "        b = sc.parallelize([(\"A\", \"a2\"), (\"C\", \"c2\"), (\"C\", \"c3\"), (\"E\", \"e1\")])\n",
    "        J = a.fullOuterJoin(b).collect\n",
    "        print(J)\n",
    "    my_join()\n",
    "\n",
    "    sc.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd2ea6",
   "metadata": {},
   "source": [
    "## Pyspark download__ AKIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d7ca06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "690541d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/bin/spark-class: line 71: /Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/bin/java: No such file or directory\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/bin/spark-class: line 96: CMD: bad array subscript\n",
      "head: illegal line count -- -1\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_98507/1905163628.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a spark session (which will run spark jobs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/quzihanwu/Desktop/UoM_Year3/Machine Learning/A1:A2_test/A2/COMP30027_2021_Project2_datasets/recipe_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sdf = spark.read.csv(\"/Users/quzihanwu/Desktop/UoM_Year3/Machine Learning/A1:A2_test/A2/COMP30027_2021_Project2_datasets/recipe_train.csv\", header=True)\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a71ad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pyspark/bin/spark-class: line 111: /Users/quzihanwu/Desktop/同盾科技实习/bin/java: No such file or directory\n",
      "/usr/local/lib/python3.9/site-packages/pyspark/bin/spark-class: line 111: exec: /Users/quzihanwu/Desktop/同盾科技实习/bin/java: cannot execute: No such file or directory\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_1776/2002673092.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc =SparkContext()\n",
    "nums= sc.parallelize([1,2,3,4])\n",
    "print(nums.take(1))\n",
    "sc.stop\n",
    "# [1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f9963c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_93436/1920404790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{fname_template}-{month}.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://s3.amazonaws.com/nyc-tlc/trip+data/{out}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{output_dir}/{out}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Done downloading {out} to {output_dir} with size {getsize(f'{output_dir}/{out}') / 1073741824:.2f}GB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from os.path import getsize\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "output_dir = \"../同盾科技实习\"\n",
    "fname_template = \"yellow_tripdata_2015\"\n",
    "\n",
    "for m in range(1, 13):\n",
    "    month = str(m).zfill(2)\n",
    "    out = f'{fname_template}-{month}.csv'\n",
    "    url = f\"https://s3.amazonaws.com/nyc-tlc/trip+data/{out}\"\n",
    "    urlretrieve(url, f\"{output_dir}/{out}\")\n",
    "\n",
    "    print(f\"Done downloading {out} to {output_dir} with size {getsize(f'{output_dir}/{out}') / 1073741824:.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3742a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/bin/spark-class: line 71: /Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/bin/java: No such file or directory\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/bin/spark-class: line 96: CMD: bad array subscript\n",
      "head: illegal line count -- -1\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_93436/3770445267.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a spark session (which will run spark jobs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/sample.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sdf = spark.read.csv('../data/sample.csv', header=True)\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58df682",
   "metadata": {},
   "source": [
    "## Tensorflow 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "597d8e45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'absl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_98507/572007099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhello\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hello, TensorFlow!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'absl'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "984ceb99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'absl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_98507/1864621634.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# if True then you install everything correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPU is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"available\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NOT AVAILABLE\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# double check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'absl'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(len(tf.config.list_physical_devices('GPU')) > 0) # if True then you install everything correctly\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\") # double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f897f3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'absl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_98507/3793406994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'absl'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412ca7f",
   "metadata": {},
   "source": [
    "## 使用朴素贝叶斯过滤垃圾邮件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "914a512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textParse(bigString):\n",
    "    import re\n",
    "    # 使用正则表达式来切分句子，其中分隔符是除单词、数字外的任意字符串\n",
    "    listOfTokens = re.split(r'\\W*', bigString)\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2]\n",
    "\n",
    "\n",
    "def spamTest():\n",
    "\n",
    "    docList = []\n",
    "    classList = []\n",
    "    fullText = []\n",
    "    for i in range(1, 26):\n",
    "        # 切分，解析数据，并归类为 1 类别\n",
    "        wordList = textParse(open('data/4.NaiveBayes/email/spam/%d.txt' % i).read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(1)\n",
    "        # 切分，解析数据，并归类为 0 类别\n",
    "        wordList = textParse(open('data/4.NaiveBayes/email/ham/%d.txt' % i).read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(0)\n",
    "    # 创建词汇表    \n",
    "    vocabList = createVocabList(docList)\n",
    "    trainingSet = range(50)\n",
    "    testSet = []\n",
    "    # 随机取 10 个邮件用来测试\n",
    "    for i in range(10):\n",
    "        # random.uniform(x, y) 随机生成一个范围为 x - y 的实数\n",
    "        randIndex = int(random.uniform(0, len(trainingSet)))\n",
    "        testSet.append(trainingSet[randIndex])\n",
    "        del(trainingSet[randIndex])\n",
    "    trainMat = []\n",
    "    trainClasses = []\n",
    "    for docIndex in trainingSet:\n",
    "        trainMat.append(setOfWords2Vec(vocabList, docList[docIndex]))\n",
    "        trainClasses.append(classList[docIndex])\n",
    "    p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses))\n",
    "    errorCount = 0\n",
    "    for docIndex in testSet:\n",
    "        wordVector = setOfWords2Vec(vocabList, docList[docIndex])\n",
    "        if classifyNB(array(wordVector), p0V, p1V, pSpam) != classList[docIndex]:\n",
    "            errorCount += 1\n",
    "    print('the errorCount is: ', errorCount)\n",
    "    print('the testSet length is :', len(testSet))\n",
    "    print('the error rate is :', float(errorCount)/len(testSet))\n",
    "\n",
    "\n",
    "# def testParseTest():\n",
    "    # print(textParse(open('/desktop/1.rtf˜').read()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2297e3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(textParse(open('/Users/quzihanwu/Desktop/1.rtf').read()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5774ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\\\rtf1\\\\ansi\\\\ansicpg936\\\\cocoartf2636\\n\\\\cocoatextscaling0\\\\cocoaplatform0{\\\\fonttbl\\\\f0\\\\fnil\\\\fcharset0 Monaco;}\\n{\\\\colortbl;\\\\red255\\\\green255\\\\blue255;\\\\red65\\\\green65\\\\blue65;\\\\red246\\\\green246\\\\blue246;}\\n{\\\\*\\\\expandedcolortbl;;\\\\cssrgb\\\\c32157\\\\c32157\\\\c32157;\\\\cssrgb\\\\c97255\\\\c97255\\\\c97255;}\\n\\\\paperw11900\\\\paperh16840\\\\margl1440\\\\margr1440\\\\vieww11520\\\\viewh8400\\\\viewkind0\\n\\\\deftab720\\n\\\\pard\\\\pardeftab720\\\\partightenfactor0\\n\\n\\\\f0\\\\fs21\\\\fsmilli10800 \\\\cf2 \\\\cb3 \\\\expnd0\\\\expndtw0\\\\kerning0\\n\\\\outl0\\\\strokewidth0 \\\\strokec2 Hi Peter,\\\\\\n\\\\\\nWith Jose out of town, do you want to\\\\\\nmeet once in a while to keep things\\\\\\ngoing and do some interesting stuff?\\\\\\n\\\\\\nLet me know\\\\\\nEugene\\\\\\nHi Peter,}'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = open('/Users/quzihanwu/Desktop/1.rtf').read()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291379d",
   "metadata": {},
   "source": [
    "## %run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b5d09af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello TongDun\n"
     ]
    }
   ],
   "source": [
    "%run '/Users/quzihanwu/Desktop/同盾科技实习/Hello TongDun.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efcae129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "%run '/Users/quzihanwu/Desktop/同盾科技实习/使用朴素贝叶斯过滤垃圾邮件.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae68057",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3161c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2a6cc",
   "metadata": {},
   "source": [
    "### checking two arrays are equal or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85a0428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = np.array([[1,2,3],[2,3,4]])\n",
    "b = np.array([[2,4],[3,6]])\n",
    "\n",
    "np.array_equal(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46c633d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31a310",
   "metadata": {},
   "source": [
    "## Lydia‘s problem with her assignment 1 in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2692d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb1291cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = ['white', 'green', 'blue', 'orange', 'white', 'red', 'red', 'gold', 'blue', 'green', 'blue', 'green', 'red', 'red', 'blue', 'blue', 'red', 'red', 'red', 'green', 'red', 'green', 'red', 'red', 'red', 'red', 'blue', 'blue', 'green', 'gold', 'red', 'white', 'white', 'white', 'red', 'red', 'gold', 'red', 'red', 'red', 'red', 'green', 'green', 'green']\n",
    "predictions = ['red', 'blue', 'red', 'gold', 'red', 'red', 'red', 'red', 'blue', 'red', 'red', 'blue', 'green', 'blue', 'green', 'red', 'red', 'red', 'red', 'green', 'red', 'blue', 'red', 'white', 'red', 'gold', 'blue', 'blue', 'red', 'red', 'red', 'red', 'blue', 'red', 'red', 'green', 'red', 'green', 'white', 'red', 'red', 'green', 'red', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69843efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize = (10,5))\n",
    "# plt.tick_params(pad=20)\n",
    "# plt.title(\"Frequency of Actual and Predicted for knn_man_5 model\", fontsize = 16)\n",
    "# plt.hist([test_labels, predictions[1]], label = ['True', 'Predicted'], color = ['blue', 'red'], histtype = 'bar', align = 'left')\n",
    "# plt.xlabel(\"Color\", fontsize = 16)\n",
    "# plt.ylabel(\"Frequency\", fontsize = 16)\n",
    "# plt.xticks(fontsize = 13)\n",
    "# plt.yticks(fontsize = 13)\n",
    "# plt.legend(loc = 'upper left', fontsize = 10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a77102e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>red</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>red</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>green</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>red</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>red</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data label\n",
       "83    red  pred\n",
       "84    red  pred\n",
       "85  green  pred\n",
       "86    red  pred\n",
       "87    red  pred"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'data': test_labels + predictions})\n",
    "df['label'] = np.concatenate((\n",
    "   np.repeat('test', len(test_labels)),\n",
    "   np.repeat('pred', len(predictions))\n",
    "))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae34155f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='data',\n",
    "   hue = 'label',\n",
    "   data=df,\n",
    "   palette='ch:.25')\n",
    "plt.xlabel(\"Color\", fontsize = 16)\n",
    "plt.ylabel(\"Frequency\", fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0e1e7",
   "metadata": {},
   "source": [
    "## downloading by ADS_project_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43e0319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done downloading yellow_tripdata_2018-07.csv to /Users/quzihanwu/Desktop/同盾科技实习 with size 0.64GB\n"
     ]
    }
   ],
   "source": [
    "from os.path import getsize\n",
    "from urllib.request import urlretrieve\n",
    "import ssl\n",
    " \n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "output_dir = \"/Users/quzihanwu/Desktop/同盾科技实习\"\n",
    "fname_template = \"yellow_tripdata_2018\"\n",
    "\n",
    "for m in range(7, 8):\n",
    "    month = str(m).zfill(2)\n",
    "    out = f'{fname_template}-{month}.csv'\n",
    "    url = f\"https://s3.amazonaws.com/nyc-tlc/trip+data/{out}\"\n",
    "    urlretrieve(url, f\"{output_dir}/{out}\")\n",
    "\n",
    "    print(f\"Done downloading {out} to {output_dir} with size {getsize(f'{output_dir}/{out}') / 1073741824:.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18640520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-01 00:28:09</td>\n",
       "      <td>2018-07-01 00:28:51</td>\n",
       "      <td>1</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-01 00:29:27</td>\n",
       "      <td>2018-07-01 00:30:17</td>\n",
       "      <td>1</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-01 00:04:19</td>\n",
       "      <td>2018-07-01 00:08:29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>211</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-01 00:14:26</td>\n",
       "      <td>2018-07-01 00:36:35</td>\n",
       "      <td>1</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>144</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-01 00:41:56</td>\n",
       "      <td>2018-07-01 00:50:54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849743</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-31 23:02:02</td>\n",
       "      <td>2018-07-31 23:06:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>141</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849744</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-31 23:15:16</td>\n",
       "      <td>2018-07-31 23:20:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849745</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-31 23:33:14</td>\n",
       "      <td>2018-07-31 23:36:44</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849746</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-31 23:47:08</td>\n",
       "      <td>2018-07-31 23:58:10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849747</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-31 23:31:47</td>\n",
       "      <td>2018-07-31 23:33:16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7849748 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2018-07-01 00:28:09   2018-07-01 00:28:51                1   \n",
       "1               1  2018-07-01 00:29:27   2018-07-01 00:30:17                1   \n",
       "2               1  2018-07-01 00:04:19   2018-07-01 00:08:29                2   \n",
       "3               1  2018-07-01 00:14:26   2018-07-01 00:36:35                1   \n",
       "4               1  2018-07-01 00:41:56   2018-07-01 00:50:54                1   \n",
       "...           ...                  ...                   ...              ...   \n",
       "7849743         2  2018-07-31 23:02:02   2018-07-31 23:06:52                1   \n",
       "7849744         2  2018-07-31 23:15:16   2018-07-31 23:20:52                1   \n",
       "7849745         2  2018-07-31 23:33:14   2018-07-31 23:36:44                1   \n",
       "7849746         2  2018-07-31 23:47:08   2018-07-31 23:58:10                1   \n",
       "7849747         2  2018-07-31 23:31:47   2018-07-31 23:33:16                1   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 5.30           1                  N           145   \n",
       "1                 5.30           1                  N           145   \n",
       "2                 0.70           1                  N           211   \n",
       "3                 4.80           1                  N           144   \n",
       "4                 1.80           1                  N           142   \n",
       "...                ...         ...                ...           ...   \n",
       "7849743           1.28           1                  N           141   \n",
       "7849744           1.60           1                  N           263   \n",
       "7849745           1.00           1                  N           239   \n",
       "7849746           2.30           1                  N           151   \n",
       "7849747           0.00           1                  N           193   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 145             2          2.5    0.5      0.5        0.00   \n",
       "1                 145             2          2.5    0.5      0.5        0.00   \n",
       "2                 144             1          5.0    0.5      0.5        1.25   \n",
       "3                 142             1         18.0    0.5      0.5        1.00   \n",
       "4                 141             2          8.5    0.5      0.5        0.00   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "7849743            75             1          6.0    0.5      0.5        0.00   \n",
       "7849744           238             2          7.0    0.5      0.5        0.00   \n",
       "7849745           143             1          5.5    0.5      0.5        1.00   \n",
       "7849746           116             2         10.5    0.5      0.5        0.00   \n",
       "7849747           193             2          0.0    0.0      0.0        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \n",
       "0                 0.0                    0.3          3.80  \n",
       "1                 0.0                    0.3          3.80  \n",
       "2                 0.0                    0.3          7.55  \n",
       "3                 0.0                    0.3         20.30  \n",
       "4                 0.0                    0.3          9.80  \n",
       "...               ...                    ...           ...  \n",
       "7849743           0.0                    0.3          7.30  \n",
       "7849744           0.0                    0.3          8.30  \n",
       "7849745           0.0                    0.3          7.80  \n",
       "7849746           0.0                    0.3         11.80  \n",
       "7849747           0.0                    0.0          0.00  \n",
       "\n",
       "[7849748 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/quzihanwu/Desktop/同盾科技实习/yellow_tripdata_2018-07.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a408e1",
   "metadata": {},
   "source": [
    "## Apriori basic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b56fc244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({5}) ---> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) ---> frozenset({5}) conf: 1.0\n",
      "frozenset({1}) ---> frozenset({3}) conf: 1.0\n"
     ]
    }
   ],
   "source": [
    "def loadDataSet():\n",
    "    return [[1,3,4],[2,3,5],[1,2,3,5],[2,5]]\n",
    "\n",
    "def createC1(dataSet):\n",
    "    C1=[]\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    return list(map(frozenset,C1))\n",
    "\n",
    "def scanD(D,CK,minSupport):\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in CK:\n",
    "            if can.issubset(tid):\n",
    "                if not can in ssCnt:ssCnt[can]=1\n",
    "                else:ssCnt[can]+=1\n",
    "    numItems = float(len(D))\n",
    "    retList = []\n",
    "    supportData={}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key]/numItems\n",
    "        if support>=minSupport:\n",
    "            retList.insert(0,key)\n",
    "        supportData[key]=support\n",
    "    return retList,supportData\n",
    "\n",
    "#频繁项集两两组合\n",
    "def aprioriGen(Lk,k):\n",
    "    retList=[]\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1,lenLk):\n",
    "            L1=list(Lk[i])[:k-2];L2=list(Lk[j])[:k-2]\n",
    "            L1.sort();L2.sort()\n",
    "            if L1==L2:\n",
    "                retList.append(Lk[i]|Lk[j])\n",
    "    return retList\n",
    "\n",
    "def apriori(dataSet,minSupport=0.5):\n",
    "    C1=createC1(dataSet)\n",
    "    D=list(map(set,dataSet))\n",
    "    L1,supportData =scanD(D,C1,minSupport)\n",
    "    L=[L1]\n",
    "    k=2\n",
    "    while(len(L[k-2])>0):\n",
    "        CK = aprioriGen(L[k-2],k)\n",
    "        Lk,supK = scanD(D,CK,minSupport)\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k+=1\n",
    "    return L,supportData\n",
    "\n",
    "#规则计算的主函数\n",
    "def generateRules(L,supportData,minConf=0.7):\n",
    "    bigRuleList = []\n",
    "    for i in range(1,len(L)):\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if(i>1):\n",
    "                rulesFromConseq(freqSet,H1,supportData,bigRuleList,minConf)\n",
    "            else:\n",
    "                calcConf(freqSet,H1,supportData,bigRuleList,minConf)\n",
    "    return bigRuleList\n",
    "\n",
    "def calcConf(freqSet,H,supportData,brl,minConf=0.7):\n",
    "    prunedH=[]\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq]\n",
    "        if conf>=minConf:\n",
    "            print (freqSet-conseq,'--->',conseq,'conf:',conf)\n",
    "            brl.append((freqSet-conseq,conseq,conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "def rulesFromConseq(freqSet,H,supportData,brl,minConf=0.7):\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet)>(m+1)):\n",
    "        Hmp1 = aprioriGen(H,m+1)\n",
    "        Hmp1 = calcConf(freqSet,Hmp1,supportData,brl,minConf)\n",
    "        if(len(Hmp1)>1):\n",
    "            rulesFromConseq(freqSet,Hmp1,supportData,brl,minConf)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    dataSet=loadDataSet()\n",
    "    L,supportData=apriori(dataSet)\n",
    "    rules = generateRules(L,supportData,minConf=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a42f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算可信度（confidence）\n",
    "def calcConf(freqSet, H\n",
    ", supportData, brl, minConf=0.7):\n",
    "    \"\"\"calcConf（对两个元素的频繁项，计算可信度，例如:  {1,2}/{1} 或者 {1,2}/{2} 看是否满足条件）\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([1, 3])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([1]), frozenset([3])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的空数组\n",
    "        minConf 最小可信度\n",
    "    Returns:\n",
    "        prunedH 记录 可信度大于阈值的集合\n",
    "    \"\"\"\n",
    "    # 记录可信度大于最小可信度（minConf）的集合\n",
    "    prunedH = []\n",
    "    for conseq in H: # 假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -> frozenset([3]) 的可信度和 frozenset([3]) -> frozenset([1]) 的可信度\n",
    "\n",
    "        # print 'confData=', freqSet, H, conseq, freqSet-conseq\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] # 支持度定义: a -> b = support(a | b) / support(a). 假设  freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])]\n",
    "        if conf >= minConf:\n",
    "            # 只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq 集合是全集）\n",
    "            print (freqSet-conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "# 递归计算频繁项集的规则\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    \"\"\"rulesFromConseq\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([2, 3, 5])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的数组\n",
    "        minConf 最小可信度\n",
    "    \"\"\"\n",
    "    # H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制\n",
    "    # 该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ...\n",
    "    # 假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "    # 那么 m = len(H[0]) 的递归的值依次为 1 2\n",
    "    # 在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)):\n",
    "        print ('freqSet******************', len(freqSet), m + 1, freqSet, H, H[0])\n",
    "        # 生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        # 第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])]\n",
    "        # 第二次 。。。没有第二次，递归条件判断时已经退出了\n",
    "        Hmp1 = aprioriGen(H, m+1)\n",
    "        # 返回可信度大于最小可信度的集合\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        print ('Hmp1=', Hmp1)\n",
    "        print ('len(Hmp1)=', len(Hmp1), 'len(freqSet)=', len(freqSet))\n",
    "        # 计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归\n",
    "        if (len(Hmp1) > 1):\n",
    "            print ('----------------------', Hmp1)\n",
    "            # print len(freqSet),  len(Hmp1[0]) + 1\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n",
    "\n",
    "# 生成关联规则\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    \"\"\"generateRules\n",
    "\n",
    "    Args:\n",
    "        L 频繁项集列表\n",
    "        supportData 频繁项集支持度的字典\n",
    "        minConf 最小置信度\n",
    "    Returns:\n",
    "        bigRuleList 可信度规则列表（关于 (A->B+置信度) 3个字段的组合）\n",
    "    \"\"\"\n",
    "    bigRuleList = []\n",
    "    # 假设 L = [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])]]\n",
    "    for i in range(1, len(L)):\n",
    "        # 获取频繁项集中每个组合的所有元素\n",
    "        for freqSet in L[i]:\n",
    "            # 假设: freqSet= frozenset([1, 3]), H1=[frozenset([1]), frozenset([3])]\n",
    "            # 组合总的元素并遍历子元素，并转化为 frozenset 集合，再存放到 list 列表中\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            # 2 个的组合，走 else, 2 个以上的组合，走 if\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "158dc04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "supportData = [[1,3,4],[2,3,5],[1,2,3,5],[2,5]]\n",
    "L = [[2,3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fd26844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateRules(L, supportData, minConf=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8851204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入支持度(0->1)\n",
      "0.676\n",
      "{frozenset({3}): 0.8333333333333334, frozenset({2}): 0.8333333333333334}\n",
      "输入支持度(0->1)\n",
      "0.916\n",
      "{}\n",
      "输入支持度(0->1)\n",
      "0.456\n",
      "{frozenset({2, 3, 5}): 0.5, frozenset({1, 2, 3}): 0.5}\n",
      "输入支持度(0->1)\n",
      "0.637\n",
      "{frozenset({1, 3}): 0.6666666666666666, frozenset({2, 3}): 0.6666666666666666, frozenset({2, 5}): 0.6666666666666666}\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: UTF-8 -*-\n",
    "\n",
    "# 加载数据\n",
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5],[3,1,5,2],[1,2,3]]\n",
    "\n",
    "# 将所有元素转换为frozenset型字典，存放到列表中\n",
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:        #去重得到单元素项\n",
    "                C1.append([item])\n",
    "    C1.sort()                           #排序\n",
    "\n",
    "    return list(map(frozenset, C1))  # 使用frozenset是为了后面可以将这些值作为字典的键 frozenset一种不可变的集合，set可变集合\n",
    "\n",
    "\n",
    "# 过滤掉支持度不符合的集合 即剪枝\n",
    "def scanD(D, Ck, minSupport):\n",
    "    ssCnt = {}                      #建立字典存储各项及数目\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):  # 判断can是否是tid的《子集》 （这里使用子集的方式来判断两者的关系）\n",
    "                ssCnt[can] = ssCnt.get(can,0)+1   #读取字典 存在can得到数值 不存在得到零 在取到的值加1 .get(要取的值，没有返回的值)\n",
    "    retList = []  # 记录支持度大于给定值的数据\n",
    "    supportData = {}  # 每个数据值的支持度\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / len(D)     #计算支持度\n",
    "        if support >= minSupport:           #和给定支持度比较\n",
    "            retList.append(key);supportData[key] = support  #将符合支持度条件的数据存储\n",
    "    return retList, supportData  # 排除不符合支持度元素后的元素 每个元素支持度# 返回频繁项集列表retList 所有元素的支持度字典\n",
    "\n",
    "\n",
    "# 生成所有可以组合的集合\n",
    "# 频繁项集列表Lk\n",
    "# 连接后项集元素个数k  [frozenset({2, 3}), frozenset({3, 5})] -> [frozenset({2, 3, 5})]\n",
    "def aprioriGen(Lk, k):\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):  # 两层循环比较Lk中的每个元素与其它元素\n",
    "        for j in range(i + 1, lenLk):\n",
    "            L1 = list(Lk[i])[:k - 2]  # 将集合转为list后 取0-k-2\n",
    "            L2 = list(Lk[j])[:k - 2]\n",
    "            L1.sort();\n",
    "            L2.sort()\n",
    "            if L1 == L2:# 该函数每次比较两个list的前k-2个元素，如果相同则求并集得到k个元素的集合\n",
    "                retList.append(Lk[i] | Lk[j])  # 求并集python求并集符号|\n",
    "    return retList  # 返回连接后的项集\n",
    "\n",
    "\n",
    "# 调用上述函数\n",
    "# 返回 所有满足大于阈值的组合 集合支持度列表\n",
    "def apriori(dataSet, minSupport):\n",
    "    D = list(map(set, dataSet))  # 转换列表记录为字典  [{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}]\n",
    "    C1 = createC1(dataSet)  # 将每个元素转会为frozenset字典    [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
    "    L1, supportData = scanD(D, C1, minSupport)  # 过滤数据\n",
    "    L = [L1]   #频繁项集的集合\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):  # 若仍有满足支持度的集合则继续做关联分析\n",
    "        Ck = aprioriGen(L[k-2], k)  # Ck候选频繁项集\n",
    "        Lk, supK = scanD(D, Ck, minSupport)  # Lk频繁项集 supk支持度\n",
    "        L.append(Lk)  # 更新L集合\n",
    "        supportData.update(supK)   # 更新字典（把新出现的集合:支持度加入到supportData中）\n",
    "        k=k+1  # 每次新组合的元素都只增加了一个，所以k也+1（k表示元素个数）\n",
    "    support = {}\n",
    "    for i in L[k - 3]:     #遍历符合支持度元素最多的项\n",
    "        support[i] = supportData.get(i)   #从字典中取出项及其支持度\n",
    "    return support   #返回项及其支持度\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while int(input('请输入序号：1 测试 0 退出\\n')):\n",
    "        print('输入支持度(0->1)')\n",
    "        support = float(input())\n",
    "        print(support)        #定义float型输入支持度\n",
    "        supp= apriori(loadDataSet(),support)\n",
    "        print(supp)                  #打印结果\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8051e39",
   "metadata": {},
   "source": [
    "## FP-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb8fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_tree的类定义\n",
    "class treeNode:\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue #节点名字\n",
    "        self.count = numOccur #节点计数值\n",
    "        self.nodeLink = None #用于链接相似的元素项\n",
    "        self.parent = parentNode      #needs to be updated\n",
    "        self.children = {} #子节点\n",
    "\n",
    "    def inc(self, numOccur):\n",
    "        '''\n",
    "        对count变量增加给定值\n",
    "        '''\n",
    "        self.count += numOccur\n",
    "\n",
    "    def disp(self, ind=1):\n",
    "        '''\n",
    "        将树以文本形式展示\n",
    "        '''\n",
    "        print ('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)\n",
    "\n",
    "# FP_tree构建函数\n",
    "def createTree(dataSet, minSup=1):\n",
    "    '''\n",
    "    创建FP树\n",
    "    '''\n",
    "    headerTable = {}\n",
    "    #第一次扫描数据集\n",
    "    for trans in dataSet:#计算item出现频数\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    headerTable = {k:v for k,v in headerTable.items() if v >= minSup}\n",
    "    freqItemSet = set(headerTable.keys())\n",
    "    #print ('freqItemSet: ',freqItemSet)\n",
    "    if len(freqItemSet) == 0: return None, None  #如果没有元素项满足要求，则退出\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] #初始化headerTable\n",
    "    #print ('headerTable: ',headerTable)\n",
    "    #第二次扫描数据集\n",
    "    retTree = treeNode('Null Set', 1, None) #创建树\n",
    "    for tranSet, count in dataSet.items():  \n",
    "        localD = {}\n",
    "        for item in tranSet:  #put transaction items in order\n",
    "            if item in freqItemSet:\n",
    "                localD[item] = headerTable[item][0]\n",
    "        if len(localD) > 0:\n",
    "            orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)]\n",
    "            updateTree(orderedItems, retTree, headerTable, count)#将排序后的item集合填充的树中\n",
    "    return retTree, headerTable #返回树型结构和头指针表\n",
    "\n",
    "def updateTree(items, inTree, headerTable, count):\n",
    "    if items[0] in inTree.children:#检查第一个元素项是否作为子节点存在\n",
    "        inTree.children[items[0]].inc(count) #存在，更新计数\n",
    "    else:   #不存在，创建一个新的treeNode,将其作为一个新的子节点加入其中\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        if headerTable[items[0]][1] == None: #更新头指针表\n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    if len(items) > 1:#不断迭代调用自身，每次调用都会删掉列表中的第一个元素\n",
    "        updateTree(items[1::], inTree.children[items[0]], headerTable, count)\n",
    "\n",
    "def updateHeader(nodeToTest, targetNode):\n",
    "    '''\n",
    "    this version does not use recursion\n",
    "    Do not use recursion to traverse a linked list!\n",
    "    更新头指针表，确保节点链接指向树中该元素项的每一个实例\n",
    "    '''\n",
    "    while (nodeToTest.nodeLink != None):    \n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode\n",
    "\n",
    "# 抽取条件模式基\n",
    "def ascendTree(leafNode, prefixPath): #迭代上溯整棵树\n",
    "    if leafNode.parent != None:\n",
    "        prefixPath.append(leafNode.name)\n",
    "        ascendTree(leafNode.parent, prefixPath)\n",
    "\n",
    "def findPrefixPath(basePat, treeNode): #treeNode comes from header table\n",
    "    condPats = {}\n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        ascendTree(treeNode, prefixPath)\n",
    "        if len(prefixPath) > 1: \n",
    "            condPats[frozenset(prefixPath[1:])] = treeNode.count\n",
    "        treeNode = treeNode.nodeLink\n",
    "    return condPats\n",
    "\n",
    "# 递归查找频繁项集\n",
    "def mineTree(inTree, headerTable, minSup, preFix, freqItemList):\n",
    "    bigL = [v[0] for v in sorted(headerTable.items(), key=lambda p: p[1][0])]# 1.排序头指针表\n",
    "    for basePat in bigL:  #从头指针表的底端开始\n",
    "        newFreqSet = preFix.copy()\n",
    "        newFreqSet.add(basePat)\n",
    "        print ('finalFrequent Item: ',newFreqSet)    #添加的频繁项列表\n",
    "        freqItemList.append(newFreqSet)\n",
    "        condPattBases = findPrefixPath(basePat, headerTable[basePat][1])\n",
    "        print ('condPattBases :',basePat, condPattBases)\n",
    "        # 2.从条件模式基创建条件FP树\n",
    "        myCondTree, myHead = createTree(condPattBases, minSup)\n",
    "#         print ('head from conditional tree: ', myHead)\n",
    "        if myHead != None: # 3.挖掘条件FP树\n",
    "            print ('conditional tree for: ',newFreqSet)\n",
    "            myCondTree.disp(1)            \n",
    "            mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b57da5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Null Set   1\n",
      "     I2   7\n",
      "       I1   2\n",
      "         I5   1\n",
      "         I4   1\n",
      "       I4   1\n",
      "       I3   4\n",
      "         I1   2\n",
      "           I5   1\n",
      "     I3   2\n",
      "       I1   2\n",
      "finalFrequent Item:  {'I5'}\n",
      "condPattBases : I5 {frozenset({'I2', 'I1'}): 1, frozenset({'I3', 'I2', 'I1'}): 1}\n",
      "conditional tree for:  {'I5'}\n",
      "   Null Set   1\n",
      "     I2   2\n",
      "       I1   2\n",
      "finalFrequent Item:  {'I5', 'I2'}\n",
      "condPattBases : I2 {}\n",
      "finalFrequent Item:  {'I5', 'I1'}\n",
      "condPattBases : I1 {frozenset({'I2'}): 2}\n",
      "conditional tree for:  {'I5', 'I1'}\n",
      "   Null Set   1\n",
      "     I2   2\n",
      "finalFrequent Item:  {'I5', 'I2', 'I1'}\n",
      "condPattBases : I2 {}\n",
      "finalFrequent Item:  {'I4'}\n",
      "condPattBases : I4 {frozenset({'I2'}): 1, frozenset({'I2', 'I1'}): 1}\n",
      "conditional tree for:  {'I4'}\n",
      "   Null Set   1\n",
      "     I2   2\n",
      "finalFrequent Item:  {'I4', 'I2'}\n",
      "condPattBases : I2 {}\n",
      "finalFrequent Item:  {'I1'}\n",
      "condPattBases : I1 {frozenset({'I2'}): 2, frozenset({'I3'}): 2, frozenset({'I3', 'I2'}): 2}\n",
      "conditional tree for:  {'I1'}\n",
      "   Null Set   1\n",
      "     I2   2\n",
      "     I3   4\n",
      "       I2   2\n",
      "finalFrequent Item:  {'I2', 'I1'}\n",
      "condPattBases : I2 {frozenset({'I3'}): 2}\n",
      "conditional tree for:  {'I2', 'I1'}\n",
      "   Null Set   1\n",
      "     I3   2\n",
      "finalFrequent Item:  {'I3', 'I2', 'I1'}\n",
      "condPattBases : I3 {}\n",
      "finalFrequent Item:  {'I3', 'I1'}\n",
      "condPattBases : I3 {}\n",
      "finalFrequent Item:  {'I3'}\n",
      "condPattBases : I3 {frozenset({'I2'}): 4}\n",
      "conditional tree for:  {'I3'}\n",
      "   Null Set   1\n",
      "     I2   4\n",
      "finalFrequent Item:  {'I3', 'I2'}\n",
      "condPattBases : I2 {}\n",
      "finalFrequent Item:  {'I2'}\n",
      "condPattBases : I2 {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'I5'},\n",
       " {'I2', 'I5'},\n",
       " {'I1', 'I5'},\n",
       " {'I1', 'I2', 'I5'},\n",
       " {'I4'},\n",
       " {'I2', 'I4'},\n",
       " {'I1'},\n",
       " {'I1', 'I2'},\n",
       " {'I1', 'I2', 'I3'},\n",
       " {'I1', 'I3'},\n",
       " {'I3'},\n",
       " {'I2', 'I3'},\n",
       " {'I2'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试1\n",
    "def loadSimpDat():\n",
    "    simpDat = [\n",
    "                ['I1','I2','I5'],\n",
    "                ['I2','I4'],\n",
    "                ['I2','I3'],\n",
    "                ['I1','I2','I4'],\n",
    "                ['I1','I3'],\n",
    "                ['I2','I3'],\n",
    "                ['I1','I3'],\n",
    "                ['I1','I2','I3','I5'],\n",
    "                ['I1','I2','I3']\n",
    "              ]\n",
    "    return simpDat\n",
    "\n",
    "def createInitSet(dataSet):  \n",
    "    retDict = {}  \n",
    "    for trans in dataSet:  \n",
    "        retDict[frozenset(trans)] = retDict.get(frozenset(trans), 0) + 1 #若没有相同事项，则为1；若有相同事项，则加1  \n",
    "    return retDict\n",
    "\n",
    "minSup = 2\n",
    "simpDat = loadSimpDat()\n",
    "initSet = createInitSet(simpDat)\n",
    "myFPtree, myHeaderTab = createTree(initSet, minSup)\n",
    "myFPtree.disp()\n",
    "myFreqList = []\n",
    "mineTree(myFPtree, myHeaderTab, minSup, set([]), myFreqList)\n",
    "\n",
    "myFreqList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d04f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Null Set   1\n",
      "     z   5\n",
      "       r   1\n",
      "         p   1\n",
      "       x   3\n",
      "         s   2\n",
      "           y   2\n",
      "             t   2\n",
      "               q   1\n",
      "         y   1\n",
      "           r   1\n",
      "             t   1\n",
      "               q   1\n",
      "                 p   1\n",
      "     x   1\n",
      "       s   1\n",
      "         r   1\n",
      "finalFrequent Item:  {'p'}\n",
      "condPattBases : p {frozenset({'z', 'r'}): 1, frozenset({'y', 'q', 'x', 'r', 't', 'z'}): 1}\n",
      "conditional tree for:  {'p'}\n",
      "   Null Set   1\n",
      "     z   1\n",
      "       r   1\n",
      "     r   1\n",
      "       z   1\n",
      "finalFrequent Item:  {'p', 'z'}\n",
      "condPattBases : z {frozenset({'r'}): 1}\n",
      "finalFrequent Item:  {'p', 'r'}\n",
      "condPattBases : r {frozenset({'z'}): 1}\n",
      "finalFrequent Item:  {'q'}\n",
      "condPattBases : q {frozenset({'y', 'x', 'r', 't', 'z'}): 1, frozenset({'s', 'y', 'x', 't', 'z'}): 1}\n",
      "conditional tree for:  {'q'}\n",
      "   Null Set   1\n",
      "     y   2\n",
      "       x   2\n",
      "         t   2\n",
      "           z   2\n",
      "finalFrequent Item:  {'q', 'y'}\n",
      "condPattBases : y {}\n",
      "finalFrequent Item:  {'q', 'x'}\n",
      "condPattBases : x {frozenset({'y'}): 2}\n",
      "conditional tree for:  {'q', 'x'}\n",
      "   Null Set   1\n",
      "     y   2\n",
      "finalFrequent Item:  {'q', 'y', 'x'}\n",
      "condPattBases : y {}\n",
      "finalFrequent Item:  {'q', 't'}\n",
      "condPattBases : t {frozenset({'y', 'x'}): 2}\n",
      "conditional tree for:  {'q', 't'}\n",
      "   Null Set   1\n",
      "     y   2\n",
      "       x   2\n",
      "finalFrequent Item:  {'q', 't', 'y'}\n",
      "condPattBases : y {}\n",
      "finalFrequent Item:  {'q', 't', 'x'}\n",
      "condPattBases : x {frozenset({'y'}): 2}\n",
      "conditional tree for:  {'q', 't', 'x'}\n",
      "   Null Set   1\n",
      "     y   2\n",
      "finalFrequent Item:  {'q', 't', 'x', 'y'}\n",
      "condPattBases : y {}\n",
      "finalFrequent Item:  {'q', 'z'}\n",
      "condPattBases : z {frozenset({'t', 'y', 'x'}): 2}\n",
      "conditional tree for:  {'q', 'z'}\n",
      "   Null Set   1\n",
      "     t   2\n",
      "       y   2\n",
      "         x   2\n",
      "finalFrequent Item:  {'q', 'z', 't'}\n",
      "condPattBases : t {}\n",
      "finalFrequent Item:  {'q', 'z', 'y'}\n",
      "condPattBases : y {frozenset({'t'}): 2}\n",
      "conditional tree for:  {'q', 'z', 'y'}\n",
      "   Null Set   1\n",
      "     t   2\n",
      "finalFrequent Item:  {'q', 'z', 't', 'y'}\n",
      "condPattBases : t {}\n",
      "finalFrequent Item:  {'q', 'z', 'x'}\n",
      "condPattBases : x {frozenset({'t', 'y'}): 2}\n",
      "conditional tree for:  {'q', 'z', 'x'}\n",
      "   Null Set   1\n",
      "     t   2\n",
      "       y   2\n",
      "finalFrequent Item:  {'q', 't', 'z', 'x'}\n",
      "condPattBases : t {}\n",
      "finalFrequent Item:  {'q', 'z', 'x', 'y'}\n",
      "condPattBases : y {frozenset({'t'}): 2}\n",
      "conditional tree for:  {'q', 'z', 'x', 'y'}\n",
      "   Null Set   1\n",
      "     t   2\n",
      "finalFrequent Item:  {'y', 'q', 'x', 't', 'z'}\n",
      "condPattBases : t {}\n",
      "finalFrequent Item:  {'r'}\n",
      "condPattBases : r {frozenset({'z'}): 1, frozenset({'s', 'x'}): 1, frozenset({'z', 'y', 'x'}): 1}\n",
      "conditional tree for:  {'r'}\n",
      "   Null Set   1\n",
      "     z   2\n",
      "       x   1\n",
      "     x   1\n",
      "finalFrequent Item:  {'z', 'r'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'x', 'r'}\n",
      "condPattBases : x {frozenset({'z'}): 1}\n",
      "finalFrequent Item:  {'s'}\n",
      "condPattBases : s {frozenset({'z', 'x'}): 2, frozenset({'x'}): 1}\n",
      "conditional tree for:  {'s'}\n",
      "   Null Set   1\n",
      "     x   3\n",
      "       z   2\n",
      "finalFrequent Item:  {'s', 'z'}\n",
      "condPattBases : z {frozenset({'x'}): 2}\n",
      "conditional tree for:  {'s', 'z'}\n",
      "   Null Set   1\n",
      "     x   2\n",
      "finalFrequent Item:  {'s', 'z', 'x'}\n",
      "condPattBases : x {}\n",
      "finalFrequent Item:  {'s', 'x'}\n",
      "condPattBases : x {}\n",
      "finalFrequent Item:  {'y'}\n",
      "condPattBases : y {frozenset({'s', 'z', 'x'}): 2, frozenset({'z', 'x'}): 1}\n",
      "conditional tree for:  {'y'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "       x   3\n",
      "         s   2\n",
      "finalFrequent Item:  {'s', 'y'}\n",
      "condPattBases : s {frozenset({'z', 'x'}): 2}\n",
      "conditional tree for:  {'s', 'y'}\n",
      "   Null Set   1\n",
      "     z   2\n",
      "       x   2\n",
      "finalFrequent Item:  {'s', 'z', 'y'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'s', 'y', 'x'}\n",
      "condPattBases : x {frozenset({'z'}): 2}\n",
      "conditional tree for:  {'s', 'y', 'x'}\n",
      "   Null Set   1\n",
      "     z   2\n",
      "finalFrequent Item:  {'s', 'z', 'y', 'x'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'z', 'y'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'y', 'x'}\n",
      "condPattBases : x {frozenset({'z'}): 3}\n",
      "conditional tree for:  {'y', 'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "finalFrequent Item:  {'z', 'y', 'x'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'t'}\n",
      "condPattBases : t {frozenset({'s', 'z', 'y', 'x'}): 2, frozenset({'z', 'y', 'x', 'r'}): 1}\n",
      "conditional tree for:  {'t'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "       y   3\n",
      "         x   3\n",
      "           s   2\n",
      "finalFrequent Item:  {'t', 's'}\n",
      "condPattBases : s {frozenset({'z', 'y', 'x'}): 2}\n",
      "conditional tree for:  {'t', 's'}\n",
      "   Null Set   1\n",
      "     z   2\n",
      "       y   2\n",
      "         x   2\n",
      "finalFrequent Item:  {'t', 'z', 's'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'t', 'y', 's'}\n",
      "condPattBases : y {frozenset({'z'}): 2}\n",
      "conditional tree for:  {'t', 'y', 's'}\n",
      "   Null Set   1\n",
      "     z   2\n",
      "finalFrequent Item:  {'t', 'z', 'y', 's'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'t', 'x', 's'}\n",
      "condPattBases : x {frozenset({'z', 'y'}): 2}\n",
      "conditional tree for:  {'t', 'x', 's'}\n",
      "   Null Set   1\n",
      "     z   2\n",
      "       y   2\n",
      "finalFrequent Item:  {'t', 'x', 'z', 's'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'t', 'x', 'y', 's'}\n",
      "condPattBases : y {frozenset({'z'}): 2}\n",
      "conditional tree for:  {'t', 'x', 'y', 's'}\n",
      "   Null Set   1\n",
      "     z   2\n",
      "finalFrequent Item:  {'s', 'y', 'x', 't', 'z'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'t', 'z'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'t', 'y'}\n",
      "condPattBases : y {frozenset({'z'}): 3}\n",
      "conditional tree for:  {'t', 'y'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "finalFrequent Item:  {'t', 'z', 'y'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'t', 'x'}\n",
      "condPattBases : x {frozenset({'z', 'y'}): 3}\n",
      "conditional tree for:  {'t', 'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "       y   3\n",
      "finalFrequent Item:  {'t', 'z', 'x'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'t', 'y', 'x'}\n",
      "condPattBases : y {frozenset({'z'}): 3}\n",
      "conditional tree for:  {'t', 'y', 'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "finalFrequent Item:  {'t', 'z', 'y', 'x'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'x'}\n",
      "condPattBases : x {frozenset({'z'}): 3}\n",
      "conditional tree for:  {'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "finalFrequent Item:  {'z', 'x'}\n",
      "condPattBases : z {}\n",
      "finalFrequent Item:  {'z'}\n",
      "condPattBases : z {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'p'},\n",
       " {'p', 'z'},\n",
       " {'p', 'r'},\n",
       " {'q'},\n",
       " {'q', 'y'},\n",
       " {'q', 'x'},\n",
       " {'q', 'x', 'y'},\n",
       " {'q', 't'},\n",
       " {'q', 't', 'y'},\n",
       " {'q', 't', 'x'},\n",
       " {'q', 't', 'x', 'y'},\n",
       " {'q', 'z'},\n",
       " {'q', 't', 'z'},\n",
       " {'q', 'y', 'z'},\n",
       " {'q', 't', 'y', 'z'},\n",
       " {'q', 'x', 'z'},\n",
       " {'q', 't', 'x', 'z'},\n",
       " {'q', 'x', 'y', 'z'},\n",
       " {'q', 't', 'x', 'y', 'z'},\n",
       " {'r'},\n",
       " {'r', 'z'},\n",
       " {'r', 'x'},\n",
       " {'s'},\n",
       " {'s', 'z'},\n",
       " {'s', 'x', 'z'},\n",
       " {'s', 'x'},\n",
       " {'y'},\n",
       " {'s', 'y'},\n",
       " {'s', 'y', 'z'},\n",
       " {'s', 'x', 'y'},\n",
       " {'s', 'x', 'y', 'z'},\n",
       " {'y', 'z'},\n",
       " {'x', 'y'},\n",
       " {'x', 'y', 'z'},\n",
       " {'t'},\n",
       " {'s', 't'},\n",
       " {'s', 't', 'z'},\n",
       " {'s', 't', 'y'},\n",
       " {'s', 't', 'y', 'z'},\n",
       " {'s', 't', 'x'},\n",
       " {'s', 't', 'x', 'z'},\n",
       " {'s', 't', 'x', 'y'},\n",
       " {'s', 't', 'x', 'y', 'z'},\n",
       " {'t', 'z'},\n",
       " {'t', 'y'},\n",
       " {'t', 'y', 'z'},\n",
       " {'t', 'x'},\n",
       " {'t', 'x', 'z'},\n",
       " {'t', 'x', 'y'},\n",
       " {'t', 'x', 'y', 'z'},\n",
       " {'x'},\n",
       " {'x', 'z'},\n",
       " {'z'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试2\n",
    "def loadSimpDat():\n",
    "    simpDat = [['r', 'z', 'h', 'j', 'p'],\n",
    "               ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'],\n",
    "               ['z'],\n",
    "               ['r', 'x', 'n', 'o', 's'],\n",
    "            #    ['r', 'x', 'n', 'o', 's'],\n",
    "               ['y', 'r', 'x', 'z', 'q', 't', 'p'],\n",
    "               ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]\n",
    "    return simpDat\n",
    "\n",
    "def createInitSet(dataSet):  \n",
    "    retDict = {}  \n",
    "    for trans in dataSet:  \n",
    "        retDict[frozenset(trans)] = retDict.get(frozenset(trans), 0) + 1 #若没有相同事项，则为1；若有相同事项，则加1  \n",
    "    return retDict\n",
    "\n",
    "minSup = 2\n",
    "simpDat = loadSimpDat()\n",
    "initSet = createInitSet(simpDat)\n",
    "myFPtree, myHeaderTab = createTree(initSet, minSup)\n",
    "myFPtree.disp()\n",
    "myFreqList = []\n",
    "mineTree(myFPtree, myHeaderTab, minSup, set([]), myFreqList)\n",
    "\n",
    "myFreqList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425b701",
   "metadata": {},
   "source": [
    "## BFS and DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe52052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "new line\n",
      "A\n",
      "C\n",
      "E\n",
      "D\n",
      "F\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "graph = {\n",
    "   'A': ['B','C'],\n",
    "   'B': ['A','C','D'],\n",
    "   'C': ['A','B','D','E'],\n",
    "   'D': ['B','C','E','F'],\n",
    "   'E': ['C','D'],\n",
    "   'F': ['D']\n",
    "}\n",
    "\n",
    "def BFS(graph, start):\n",
    "   queue = []\n",
    "   queue.append(start)\n",
    "   seen = set()\n",
    "   seen.add(start)\n",
    "\n",
    "   while(len(queue) > 0):\n",
    "      vertex = queue.pop(0)\n",
    "      nodes = graph[vertex]\n",
    "      for w in nodes:\n",
    "         if w not in seen:\n",
    "            queue.append(w)\n",
    "            seen.add(w)\n",
    "      print(vertex)\n",
    "\n",
    "def DFS(graph, start):\n",
    "   stack = []\n",
    "   stack.append(start)\n",
    "   seen = set()\n",
    "   seen.add(start)\n",
    "\n",
    "   while(len(stack) > 0):\n",
    "      vertex = stack.pop()\n",
    "      nodes = graph[vertex]\n",
    "      for w in nodes:\n",
    "         if w not in seen:\n",
    "            stack.append(w)\n",
    "            seen.add(w)\n",
    "      print(vertex)\n",
    "\n",
    "BFS(graph, 'A')\n",
    "print('new line')\n",
    "DFS(graph, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490f266",
   "metadata": {},
   "source": [
    "## Github readme file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33576d28",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    <a href=\"https://discord.gg/U6uYEfBjqX\" target=\"_blank\"><img height='25' src=\"https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white\" target=\"_blank\"></a>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "<!-- <p align=\"left\" margin> <img src=\"https://komarev.com/ghpvc/?username=chuangyu-hscy&label=Profile%20views&color=fd428d&style=badge\" alt=\"chuangyu-hscy\" /></p> -->\n",
    "\n",
    "<!-- title/welcome words -->\n",
    "<!-- <h1 align='center'>~ Hello (ฅ'ω'ฅ) ~ <br /> This is Rin Huang</h1>\n",
    " -->\n",
    "\n",
    "\n",
    "<div align='center'><img src=\"https://capsule-render.vercel.app/api?type=waving&color=9be9e4&height=150&section=header&text=~%Hello %(ฅ'ω'ฅ)% ~%20 This %is % Rin %Huang&fontSize=25&fontColor=fff\" width='650' /></div>\n",
    "\n",
    "\n",
    "\n",
    "<!-- social media links -->\n",
    "<div align='center'>\n",
    "  <img width=30 src=\"https://c.tenor.com/CsqnkjKnojgAAAAi/dm4uz3-foekoe.gif\" />\n",
    "  <a href='https://www.github.com/chuangyu-hscy'><img height=25 src='https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white' /></a>\n",
    "  <a href=\"https://www.instagram.com/chuangyu_hscy/\" target=\"_blank\"><img height='25' src=\"https://img.shields.io/badge/-Instagram-%23E4405F?style=for-the-badge&logo=instagram&logoColor=white\" target=\"_blank\"></a>\n",
    "  <a href='https://www.linkedin.com/in/chuangyu-hscy/' alt='rin huang linkedin'><img src='https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white' alt='linkedin link' height='25' /></a>\n",
    "<!--   <a href='https://www.instagram.com/chuangyu_hscy/' alt='rin huang instagram'><img src='https://img.shields.io/badge/Instagram-E4405F?style=for-the-badge&logo=instagram&logoColor=white' alt='instagram' height='25'></a> -->\n",
    "  <a href=\"https://www.overleaf.com/read/crhyszcrnykm\" alt=\"\"><img src=\"https://img.shields.io/badge/Overleaf-47A141?style=for-the-badge&logo=Overleaf&logoColor=white\" alt='overleaf' height='25' /></a>\n",
    " <a href=\"https://discord.gg/U6uYEfBjqX\" target=\"_blank\"><img height='25' src=\"https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white\" target=\"_blank\"></a> \n",
    "  <a href = \"mailto:huang@rin.contact\"><img height='25' src=\"https://img.shields.io/badge/-Gmail-%23333?style=for-the-badge&logo=gmail&logoColor=white\" target=\"_blank\"></a>\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<!-- short description -->\n",
    "<p align='center'><img src='https://c.tenor.com/DehpokEAjJEAAAAi/cat-loading.gif' width=50/> A Data Science student study in the <a href='https://www.unimelb.edu.au/' alt='unimelb'>Unimelb</a> <img src='https://c.tenor.com/nwE8h9HLqZUAAAAj/flag-country.gif' width=20 /> </p>\n",
    "<br />\n",
    "\n",
    "<!-- github stats -->\n",
    "\n",
    "<div align='center'>\n",
    "  <img src='https://github-readme-stats.vercel.app/api?username=chuangyu-hscy&show_icons=true&count_private=true&theme=radical' alt='github stats' height=125>\n",
    "  <img  height='125' src=\"https://github-readme-streak-stats.herokuapp.com/?user=chuangyu-hscy&theme=radical\" alt=\"chuangyu-hscy\" />\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<!-- <div align='center'>\n",
    "  <img width='275' src=\"https://github-readme-stats.vercel.app/api/top-langs/?username=chuangyu-hscy&layout=compact&langs_count=7&theme=radical\"/>\n",
    "</div> -->\n",
    " \n",
    "<!-- \n",
    "<div align='center'><img src='https://github-profile-summary-cards.vercel.app/api/cards/profile-details?username=chuangyu-hscy&theme=monokai' alt='github stats' width='350'></div> -->\n",
    "\n",
    "<div align='center' text-content='justify' >  \n",
    "  <p>Interesting and passionating in data science <img src='https://c.tenor.com/1vhgkHU7lI0AAAAi/takodachi-ina.gif' width=45/></p>\n",
    "  <p>Wanna use data improve people's lives ♬ヽ(*・ω・)ﾉ  </p>\n",
    "</div>\n",
    "<br />\n",
    " \n",
    "<div align='center'>\n",
    "<img width='650' align='center' src=\"https://github.com/chuangyu-hscy/chuangyu-hscy/blob/output/github-contribution-grid-snake.svg\" alt='snake animation' />\n",
    "\n",
    "<!-- <img width=100  src=\"https://c.tenor.com/cBiRfjAlMgYAAAAi/bongocat-happy.gif\" align='center'/> -->\n",
    "\n",
    "<br />\n",
    "<img src='https://c.tenor.com/3-zt2Wtxch4AAAAC/rainbow-rainbow-bar.gif' width=650 align='center' height=2>\n",
    "    \n",
    "\n",
    "<b><p align='center'>SEE PINNED REPOS <img align='center' src=\"https://c.tenor.com/k2GZAYWuTS4AAAAi/backhand-index-pointing-down-joypixels.gif\" width=45 /></p></b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd10a33f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (338111843.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_39603/338111843.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <!-- <p align=\"left\" margin> <img src=\"https://komarev.com/ghpvc/?username=chuangyu-hscy&label=Profile%20views&color=fd428d&style=badge\" alt=\"chuangyu-hscy\" /></p> -->\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<!-- <p align=\"left\" margin> <img src=\"https://komarev.com/ghpvc/?username=chuangyu-hscy&label=Profile%20views&color=fd428d&style=badge\" alt=\"chuangyu-hscy\" /></p> -->\n",
    "<!-- title/welcome words -->\n",
    "<!-- <h1 align='center'> Hello ~ <br /> This is QUZIHAN WU 邬屈子涵</h1>\n",
    " -->\n",
    "<div align='center'><img src=\"https://capsule-render.vercel.app/api?type=waving&color=E9CDF5&height=150&section=header&text=Hello ~%20 This %is % QUZIHAN %WU %邬屈子涵&fontSize=25&fontColor=666666\" width='650' /></div>\n",
    "\n",
    "\n",
    "<!-- social media links -->\n",
    "<div align='center'>\n",
    "  <img width=30 src=\"https://c.tenor.com/CsqnkjKnojgAAAAi/dm4uz3-foekoe.gif\" />\n",
    "  <a href='https://github.com/QUZIHANWU?tab=projects'><img height=25 src='https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white' /></a>\n",
    "  <a href=\"https://www.instagram.com/marzeguptreetin/\" target=\"_blank\"><img height='25' src=\"https://img.shields.io/badge/-Instagram-%23E4405F?style=for-the-badge&logo=instagram&logoColor=white\" target=\"_blank\"></a>\n",
    "  <a href='https://www.linkedin.cn/injobs/in/%E5%AD%90%E6%B6%B5-%E9%82%AC%E5%B1%88-868463210' alt='rin huang linkedin'><img src='https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white' alt='linkedin link' height='25' /></a>\n",
    "<!--   <a href='https://www.instagram.com/marzeguptreetin/' alt='marzeguptreetin instagram'><img src='https://img.shields.io/badge/Instagram-E4405F?style=for-the-badge&logo=instagram&logoColor=white' alt='instagram' height='25'></a> -->\n",
    "  <a href = \"quzihanwu.0712@gmail.com\"><img height='25' src=\"https://img.shields.io/badge/-Gmail-%23333?style=for-the-badge&logo=gmail&logoColor=white\" target=\"_blank\"></a>\n",
    "  <a href=\"https://discord.com/channels/@me\" target=\"_blank\"><img height='25' src=\"https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white\" target=\"_blank\"></a> \n",
    "</div>\n",
    "\n",
    "\n",
    "<br />\n",
    "<!-- short description -->\n",
    "<p align='center'> A Data Science student study in the <a href='https://www.unimelb.edu.au/' alt='unimelb'>Unimelb</a> <img src='https://c.tenor.com/nwE8h9HLqZUAAAAj/flag-country.gif' width=20 /> </p>\n",
    "<p align='center'> Currently, work in the <a href='https://www.tongdun.cn/?r=pp' alt='杭州同盾科技'>杭州同盾科技</a> <img src='https://tenor.com/view/china-flag-gif-11411743' width=20 /> </p>\n",
    "<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803431ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1672584770.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_39603/1672584770.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://api.spencerwoo.com/substats/?source=discord&queryKey=Martin_Wu#9496\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<div align=\"center\">\n",
    "<span>  </span>\n",
    "<img height=\"170px\" src=\"https://github-readme-stats.vercel.app/api?username=Achuan-2\" /><span>  </span><img height=\"170px\" src=\"https://github-readme-stats.vercel.app/api/top-langs/?username=Achuan-2&layout=compact&langs_count=8\" />\n",
    "<span>  </span>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
